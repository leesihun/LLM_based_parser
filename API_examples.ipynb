{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# HE Team LLM Assistant - API Examples\n",
    "\n",
    "**Version**: 2.2.0\n",
    "\n",
    "**Base URL**: `http://localhost:8000` (change to your server IP if needed)\n",
    "\n",
    "This notebook demonstrates all available API endpoints.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Backend server running: `python run_backend.py`\n",
    "2. Valid user credentials\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Client Setup](#client-setup)\n",
    "2. [Authentication](#authentication)\n",
    "3. [Normal Chat](#normal-chat)\n",
    "4. [RAG Chat](#rag-chat)\n",
    "5. [Web Search Chat](#web-search)\n",
    "6. [JSON Analysis](#json-analysis)\n",
    "7. [File Upload & Analysis](#file-analysis)\n",
    "8. [Conversation Management](#conversations)\n",
    "9. [System Health](#health)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "client-setup",
   "metadata": {},
   "source": [
    "## 1. Client Setup\n",
    "\n",
    "Complete Python client with all API methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "client-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class LLMClient:\n",
    "    \"\"\"Complete API client for HE Team LLM Assistant.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = \"http://localhost:8000\"):\n",
    "        self.base_url = base_url\n",
    "        self.session_token = None\n",
    "        self.headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    def login(self, username: str, password: str) -> bool:\n",
    "        \"\"\"Login and obtain session token.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/api/auth/login\",\n",
    "            headers=self.headers,\n",
    "            json={\"username\": username, \"password\": password}\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            self.session_token = data[\"session_token\"]\n",
    "            self.headers[\"Authorization\"] = f\"Bearer {self.session_token}\"\n",
    "            print(f\"✓ Login successful\")\n",
    "            print(f\"  User: {data['user']['username']}\")\n",
    "            print(f\"  Role: {data['user']['role']}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"✗ Login failed: {response.status_code}\")\n",
    "            return False\n",
    "    \n",
    "    def logout(self) -> bool:\n",
    "        \"\"\"Logout and invalidate token.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/api/auth/logout\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            self.session_token = None\n",
    "            del self.headers[\"Authorization\"]\n",
    "            print(\"✓ Logged out\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def chat(self, message: str, session_id=None, chat_type=\"normal\", \n",
    "             json_data=None, json_path=None, temperature=None) -> dict:\n",
    "        \"\"\"Send a message to the LLM API.\n",
    "        \n",
    "        Args:\n",
    "            message: Your question/message\n",
    "            session_id: Continue existing conversation (optional)\n",
    "            chat_type: \"normal\", \"rag\", \"web_search\", or \"json\"\n",
    "            json_data: JSON object for analysis (for json mode)\n",
    "            json_path: Path to JSON file (for json mode)\n",
    "            temperature: Override default temperature (0.0-1.0)\n",
    "        \"\"\"\n",
    "        endpoint_map = {\n",
    "            \"normal\": \"/api/chat\",\n",
    "            \"rag\": \"/api/chat/rag\",\n",
    "            \"web_search\": \"/api/chat/web-search\",\n",
    "            \"json\": \"/api/chat/with-json\"\n",
    "        }\n",
    "        endpoint = endpoint_map.get(chat_type, \"/api/chat\")\n",
    "\n",
    "        if chat_type == \"json\":\n",
    "            # Load JSON from file if path provided\n",
    "            if json_path and not json_data:\n",
    "                with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    json_data = json.load(f)\n",
    "            \n",
    "            payload = {\n",
    "                \"message\": message,\n",
    "                \"json_data\": json_data,\n",
    "                \"session_id\": session_id,\n",
    "                \"temperature\": temperature if temperature is not None else 0.0\n",
    "            }\n",
    "        else:\n",
    "            payload = {\"message\": message}\n",
    "            if session_id:\n",
    "                payload[\"session_id\"] = session_id\n",
    "            if temperature is not None:\n",
    "                payload[\"temperature\"] = temperature\n",
    "\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}{endpoint}\",\n",
    "            headers=self.headers,\n",
    "            json=payload,\n",
    "            timeout=600\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"✗ Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return None\n",
    "    \n",
    "    def upload_file(self, file_path: str) -> dict:\n",
    "        \"\"\"Upload a file for analysis.\"\"\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            files = {'file': f}\n",
    "            headers = {\"Authorization\": self.headers.get(\"Authorization\")}\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/api/files/upload\",\n",
    "                headers=headers,\n",
    "                files=files\n",
    "            )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"✓ File uploaded: {data['original_name']}\")\n",
    "            print(f\"  File ID: {data['file_id']}\")\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"✗ Upload failed: {response.status_code}\")\n",
    "            return None\n",
    "    \n",
    "    def list_files(self) -> list:\n",
    "        \"\"\"List all uploaded files.\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"{self.base_url}/api/files\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.json().get(\"files\", [])\n",
    "    \n",
    "    def analyze_file(self, file_id: str, question: str, session_id=None) -> dict:\n",
    "        \"\"\"Ask questions about an uploaded file.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/api/files/{file_id}/read\",\n",
    "            headers=self.headers,\n",
    "            json={\"question\": question, \"session_id\": session_id}\n",
    "        )\n",
    "        return response.json() if response.status_code == 200 else None\n",
    "    \n",
    "    def delete_file(self, file_id: str) -> bool:\n",
    "        \"\"\"Delete an uploaded file.\"\"\"\n",
    "        response = requests.delete(\n",
    "            f\"{self.base_url}/api/files/{file_id}\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.status_code == 200\n",
    "    \n",
    "    def list_sessions(self) -> list:\n",
    "        \"\"\"List all conversation sessions.\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"{self.base_url}/api/chat/sessions\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.json().get(\"sessions\", [])\n",
    "    \n",
    "    def get_session(self, session_id: str) -> dict:\n",
    "        \"\"\"Get conversation history.\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"{self.base_url}/api/chat/sessions/{session_id}\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.json()\n",
    "    \n",
    "    def delete_session(self, session_id: str) -> bool:\n",
    "        \"\"\"Delete a conversation session.\"\"\"\n",
    "        response = requests.delete(\n",
    "            f\"{self.base_url}/api/chat/sessions/{session_id}\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.json().get(\"deleted\", False)\n",
    "    \n",
    "    def health_check(self) -> dict:\n",
    "        \"\"\"Check system health.\"\"\"\n",
    "        response = requests.get(f\"{self.base_url}/health\")\n",
    "        return response.json()\n",
    "    \n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Get current configuration.\"\"\"\n",
    "        response = requests.get(f\"{self.base_url}/api/config\")\n",
    "        return response.json()\n",
    "    \n",
    "    def list_models(self) -> list:\n",
    "        \"\"\"List available LLM models.\"\"\"\n",
    "        response = requests.get(f\"{self.base_url}/api/models\")\n",
    "        return response.json().get(\"models\", [])\n",
    "\n",
    "print(\"✓ LLMClient class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auth-section",
   "metadata": {},
   "source": [
    "## 2. Authentication\n",
    "\n",
    "Initialize client and login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client instance\n",
    "# Change base_url to your server IP if needed\n",
    "client = LLMClient(base_url=\"http://localhost:8000\")\n",
    "\n",
    "# Login with your credentials\n",
    "client.login(\"guest\", \"guest_test1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "health-section",
   "metadata": {},
   "source": [
    "## 3. System Health Check\n",
    "\n",
    "Check if the system is running properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "health-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "health = client.health_check()\n",
    "print(json.dumps(health, indent=2))\n",
    "\n",
    "# Check specific features\n",
    "print(f\"\\nStatus: {health['status']}\")\n",
    "print(f\"Model: {health.get('model', 'Unknown')}\")\n",
    "print(f\"Web Search: {'Enabled' if health.get('web_search_enabled') else 'Disabled'}\")\n",
    "print(f\"RAG System: {'Ready' if health.get('rag_enabled') else 'Not configured'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-chat-section",
   "metadata": {},
   "source": [
    "## 4. Normal Chat\n",
    "\n",
    "Basic conversation with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new conversation\n",
    "result = client.chat(\"Hello! Can you explain what you can help me with?\")\n",
    "\n",
    "if result:\n",
    "    session_id = result[\"session_id\"]\n",
    "    print(\"AI Response:\")\n",
    "    print(result['response'])\n",
    "    print(f\"\\nSession ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continue-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation\n",
    "result = client.chat(\n",
    "    \"What programming languages can you help with?\",\n",
    "    session_id=session_id\n",
    ")\n",
    "\n",
    "print(\"AI Response:\")\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag-section",
   "metadata": {},
   "source": [
    "## 5. RAG Chat\n",
    "\n",
    "Search knowledge base and answer based on documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rag-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG-enabled chat\n",
    "result = client.chat(\n",
    "    \"What documents do we have about warpage?\",\n",
    "    chat_type=\"rag\"\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(\"AI Response (with RAG):\")\n",
    "    print(result['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "web-search-section",
   "metadata": {},
   "source": [
    "## 6. Web Search Chat\n",
    "\n",
    "Get current information from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "web-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web search chat\n",
    "result = client.chat(\n",
    "    \"What are the latest developments in large language models?\",\n",
    "    chat_type=\"web_search\"\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(\"AI Response (with web search):\")\n",
    "    print(result['response'])\n",
    "    print(f\"\\nKeyword extraction used: {result.get('keyword_extraction_used', False)}\")\n",
    "    print(f\"Successful query: {result.get('successful_query', 'N/A')}\")\n",
    "    \n",
    "    if result.get('search_results'):\n",
    "        print(f\"\\nSearch results found: {len(result['search_results'])}\")\n",
    "        for i, sr in enumerate(result['search_results'][:3], 1):\n",
    "            print(f\"\\n{i}. {sr['title']}\")\n",
    "            print(f\"   URL: {sr['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-section",
   "metadata": {},
   "source": [
    "## 7. JSON Analysis\n",
    "\n",
    "High-accuracy JSON analysis with zero-hallucination mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "json-inline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Inline JSON data\n",
    "json_data = {\n",
    "    \"materials\": [\n",
    "        {\"id\": \"ABC123\", \"name\": \"Material A\", \"warpage\": 0.45, \"temperature\": 245},\n",
    "        {\"id\": \"XYZ789\", \"name\": \"Material B\", \"warpage\": 1.23, \"temperature\": 280},\n",
    "        {\"id\": \"DEF456\", \"name\": \"Material C\", \"warpage\": 0.89, \"temperature\": 260}\n",
    "    ]\n",
    "}\n",
    "\n",
    "result = client.chat(\n",
    "    \"Which material has the lowest warpage and what is its temperature?\",\n",
    "    chat_type=\"json\",\n",
    "    json_data=json_data\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(\"AI Response:\")\n",
    "    print(result['response'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Numeric Summary (auto-generated):\")\n",
    "    print(\"=\"*60)\n",
    "    print(result.get('numeric_summary', 'N/A'))\n",
    "    \n",
    "    if result.get('validation_notes'):\n",
    "        vn = result['validation_notes']\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Validation:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Validated: {vn.get('validated', False)}\")\n",
    "        if vn.get('warnings'):\n",
    "            print(\"Warnings:\", vn['warnings'])\n",
    "        if vn.get('info'):\n",
    "            print(\"Info:\", vn['info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "json-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: JSON from file\n",
    "# Make sure the file exists at this path\n",
    "json_file_path = \"./data/sample_data.json\"  # Change this to your JSON file path\n",
    "\n",
    "# Uncomment if you have a JSON file:\n",
    "# result = client.chat(\n",
    "#     \"Summarize the data and find the maximum value\",\n",
    "#     chat_type=\"json\",\n",
    "#     json_path=json_file_path\n",
    "# )\n",
    "# print(result['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file-section",
   "metadata": {},
   "source": [
    "## 8. File Upload & Analysis\n",
    "\n",
    "Upload files and ask questions about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List currently uploaded files\n",
    "files = client.list_files()\n",
    "print(f\"Uploaded files: {len(files)}\")\n",
    "for f in files:\n",
    "    print(f\"  - {f['original_name']} (ID: {f['file_id']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file\n",
    "# Change this to your file path\n",
    "file_path = \"./sample_document.pdf\"  # PDF, DOCX, TXT, etc.\n",
    "\n",
    "# Uncomment if you have a file:\n",
    "# upload_result = client.upload_file(file_path)\n",
    "# if upload_result:\n",
    "#     file_id = upload_result['file_id']\n",
    "#     print(f\"File uploaded with ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze uploaded file\n",
    "# Use the file_id from upload or list_files()\n",
    "\n",
    "# Uncomment and set your file_id:\n",
    "# file_id = \"your-file-id-here\"\n",
    "# result = client.analyze_file(\n",
    "#     file_id,\n",
    "#     \"What is the main topic of this document?\"\n",
    "# )\n",
    "# if result:\n",
    "#     print(\"AI Response:\")\n",
    "#     print(result['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversation-section",
   "metadata": {},
   "source": [
    "## 9. Conversation Management\n",
    "\n",
    "List, view, and manage conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all sessions\n",
    "sessions = client.list_sessions()\n",
    "print(f\"Total sessions: {len(sessions)}\")\n",
    "for s in sessions[:5]:  # Show first 5\n",
    "    print(f\"  Session: {s['session_id']}\")\n",
    "    print(f\"    Messages: {s.get('message_count', 'Unknown')}\")\n",
    "    print(f\"    Created: {s.get('created_at', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "view-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View specific session history\n",
    "if session_id:  # From earlier chat\n",
    "    history = client.get_session(session_id)\n",
    "    print(f\"Session: {session_id}\")\n",
    "    print(f\"Messages: {len(history.get('history', []))}\\n\")\n",
    "    \n",
    "    for msg in history.get('history', []):\n",
    "        role = msg['role'].upper()\n",
    "        content = msg['content'][:100] + \"...\" if len(msg['content']) > 100 else msg['content']\n",
    "        print(f\"{role}: {content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-section",
   "metadata": {},
   "source": [
    "## 10. Available Models\n",
    "\n",
    "List LLM models available on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available models\n",
    "models = client.list_models()\n",
    "print(f\"Available models: {len(models)}\\n\")\n",
    "for m in models:\n",
    "    print(f\"  - {m['name']}\")\n",
    "    print(f\"    Size: {m.get('size', 'Unknown')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section",
   "metadata": {},
   "source": [
    "## 11. Cleanup\n",
    "\n",
    "Logout when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logout\n",
    "client.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ Authentication (login/logout)\n",
    "2. ✅ Health checks\n",
    "3. ✅ Normal chat conversations\n",
    "4. ✅ RAG-enabled chat (knowledge base)\n",
    "5. ✅ Web search integration\n",
    "6. ✅ High-accuracy JSON analysis\n",
    "7. ✅ File upload and analysis\n",
    "8. ✅ Conversation management\n",
    "9. ✅ Model listing\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- See [API_REFERENCE.md](API_REFERENCE.md) for complete API documentation\n",
    "- Check [docs/QUICK_START.md](docs/QUICK_START.md) for getting started guide\n",
    "- Review [docs/README_SEPARATED_SERVERS.md](docs/README_SEPARATED_SERVERS.md) for deployment\n",
    "\n",
    "### Support\n",
    "\n",
    "For questions or issues, contact: s.hun.lee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
