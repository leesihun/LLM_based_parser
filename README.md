# LLM-based Parser for Cellphone Reviews

A comprehensive system that uses Ollama LLMs with RAG (Retrieval-Augmented Generation) to analyze cellphone reviews from Excel files.

## üöÄ Features

- **Excel Data Processing**: Reads positive and negative cellphone reviews from configurable Excel files
- **RAG System**: Vector database with ChromaDB and sentence transformers for context retrieval
- **Ollama Integration**: Dynamic model selection and automatic model management
- **Multilingual Support**: Korean and English language support with automatic detection
- **Dual Interface**: Streamlit web app and command-line interface
- **Smart Configuration**: Environment-based settings with flexible parameters

## üìã Quick Start

### Prerequisites
- Python 3.8+
- [Ollama](https://ollama.ai) installed and running
- Excel files containing review data in the `data/` directory (filenames configurable via .env)

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/LLM_based_parser.git
cd LLM_based_parser

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup configuration (optional)
cp .env.example .env

# Initialize the RAG system
python cli.py setup
```

### Usage

#### Web Interface
```bash
streamlit run src/main.py
# Access at http://localhost:8501
```

#### Command Line
```bash
# Interactive query mode
python cli.py query

# Use specific model
python cli.py query --model llama3

# Check system status
python cli.py status
```

## üèóÔ∏è Architecture

The system implements a RAG architecture with the following components:

1. **Data Processing**: Excel file reader with flexible column detection
2. **Vector Database**: ChromaDB for persistent embeddings storage
3. **LLM Integration**: Ollama client with automatic model management
4. **User Interfaces**: Streamlit web app and CLI for different use cases

## üìÅ Project Structure

```
LLM_based_parser/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ excel_reader.py      # Excel file processing
‚îÇ   ‚îú‚îÄ‚îÄ rag_system.py        # RAG implementation
‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py     # Ollama integration
‚îÇ   ‚îî‚îÄ‚îÄ main.py              # Streamlit interface
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py            # Configuration management
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ [positive file].xlsx  # Positive reviews (configurable filename)
‚îÇ   ‚îî‚îÄ‚îÄ [negative file].xlsx  # Negative reviews (configurable filename)
‚îú‚îÄ‚îÄ requirements.txt         # Dependencies
‚îú‚îÄ‚îÄ cli.py                  # Command-line interface
‚îî‚îÄ‚îÄ README.md               # This file
```

## ‚öôÔ∏è Configuration

Key settings in `.env`:

```bash
# RAG Settings
RAG_COLLECTION_NAME=cellphone_reviews
EMBEDDING_MODEL=all-MiniLM-L6-v2
SIMILARITY_THRESHOLD=0.8

# Ollama Settings
DEFAULT_OLLAMA_MODEL=llama3
OLLAMA_HOST=localhost:11434

# Generation Settings
DEFAULT_TEMPERATURE=0.7
MAX_TOKENS=1000
```

## üìä Data Requirements

Place your Excel files in the `data/` directory. Default filenames are:
- `fold_positive.xlsx`: Contains positive cellphone reviews  
- `fold_negative.xlsx`: Contains negative cellphone reviews

**Custom Filenames**: Configure different filenames in your `.env` file:
```bash
POSITIVE_FILENAME=your_positive_file.xlsx
NEGATIVE_FILENAME=your_negative_file.xlsx
```

The system automatically detects review text columns (`review`, `text`, `comment`, `content`, etc.).

## ü§ñ Ollama Models

### Korean Language Support
For Korean language processing, install Korean-capable models:

```bash
# Recommended for Korean
ollama pull qwen2      # Best Korean support
ollama pull llama3     # Good multilingual support
ollama pull gemma2     # Google's multilingual model

# List available models
ollama list

# Other useful models
ollama pull mistral
ollama pull codellama
```

### Language Configuration
The system automatically detects Korean text and switches language context. You can also manually configure:

```bash
# In .env file
POSITIVE_FILENAME=my_positive_reviews.xlsx
NEGATIVE_FILENAME=my_negative_reviews.xlsx
DEFAULT_OLLAMA_MODEL=qwen2
DEFAULT_LANGUAGE=auto  # Options: auto, en, ko
EMBEDDING_MODEL=nomic-embed-text
```

## üîß Development

See [CLAUDE.md](CLAUDE.md) for detailed development guidelines and architecture notes.

## üö® Troubleshooting

### Common Issues

#### "Failed to connect to Ollama" Error
```
ERROR: rag_system: Error generating embedding for text: Failed to connect to Ollama
```

**Solutions:**
1. **Check Ollama is running:**
   ```bash
   ollama serve
   ```

2. **Verify connection:**
   ```bash
   curl http://localhost:11434/api/tags
   ```

3. **Check host configuration in .env:**
   ```bash
   OLLAMA_HOST=localhost:11434  # Default
   ```

4. **Test embedding model availability:**
   ```bash
   ollama list
   ollama pull nomic-embed-text:latest
   ```

#### Model Not Found Error
```
ERROR: Model 'nomic-embed-text:latest' not available
```

**Solution:**
```bash
ollama pull nomic-embed-text:latest
```

#### Excel File Not Found
**Check your .env configuration:**
```bash
POSITIVE_FILENAME=your_positive_file.xlsx
NEGATIVE_FILENAME=your_negative_file.xlsx
```

**Verify files exist in data/ directory**

#### Permission Errors on ChromaDB
**Solution:**
```bash
rm -rf data/chromadb/  # Remove existing database
python cli.py setup    # Reinitialize
```

### Debug Mode
Enable debug logging by setting:
```bash
export PYTHONPATH=$PYTHONPATH:.
python -c "import logging; logging.basicConfig(level=logging.DEBUG)"
python cli.py setup
```

## üìÑ License

MIT License

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.